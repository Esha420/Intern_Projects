{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c2c334ea-b69b-4e2b-9ca8-d9c15c14d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r'C:\\Users\\acer\\Learning\\Python_Contents\\DataSets\\retail_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "58e30930-a4bd-4b00-9271-dc0bdde1652e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction_ID                8691788.0\n",
      "Customer_ID                     37249.0\n",
      "Name                Michelle Harrington\n",
      "Email                 Ebony39@gmail.com\n",
      "Phone                      1414786801.0\n",
      "Address               3959 Amanda Burgs\n",
      "City                           Dortmund\n",
      "State                            Berlin\n",
      "Zipcode                         77985.0\n",
      "Country                         Germany\n",
      "Age                                21.0\n",
      "Gender                             Male\n",
      "Income                              Low\n",
      "Customer_Segment                Regular\n",
      "Date                          9/18/2023\n",
      "Year                             2023.0\n",
      "Month                         September\n",
      "Time                           22:03:55\n",
      "Total_Purchases                     3.0\n",
      "Amount                       108.028757\n",
      "Total_Amount                  324.08627\n",
      "Product_Category               Clothing\n",
      "Product_Brand                      Nike\n",
      "Product_Type                     Shorts\n",
      "Feedback                      Excellent\n",
      "Shipping_Method                Same-Day\n",
      "Payment_Method               Debit Card\n",
      "Order_Status                    Shipped\n",
      "Ratings                             5.0\n",
      "products                 Cycling shorts\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "da54239b-0fe4-4483-a0d9-c9a363c73b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Transaction_ID', 'Customer_ID', 'Name', 'Email', 'Phone', 'Address', 'City', 'State', 'Zipcode', 'Country', 'Age', 'Gender', 'Income', 'Customer_Segment', 'Date', 'Year', 'Month', 'Time', 'Total_Purchases', 'Amount', 'Total_Amount', 'Product_Category', 'Product_Brand', 'Product_Type', 'Feedback', 'Shipping_Method', 'Payment_Method', 'Order_Status', 'Ratings', 'products']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d26373f7-14fa-4af3-ac53-6a4c59a33481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and parse dates\n",
    "def clean_date(date_str):\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, format='%m/%d/%Y')\n",
    "    except:\n",
    "        return pd.to_datetime(date_str, format='%d-%m-%y')\n",
    "\n",
    "df['Date'] = df['Date'].apply(clean_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d1b56649-9bca-4975-9420-e38d72aeddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time features\n",
    "df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
    "df['DayOfMonth'] = df['Date'].dt.day\n",
    "df['IsWeekend'] = df['DayOfWeek'].isin([5, 6]).astype(int)\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Hour'] = pd.to_datetime(df['Time'], format='%H:%M:%S').dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f215da88-9319-4590-b80d-247277d0e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle categorical data\n",
    "cat_cols = ['Gender', 'Customer_Segment', 'Product_Category', 'Payment_Method', 'Shipping_Method', 'Order_Status']\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "# Convert Income to numeric\n",
    "df['Income'] = pd.to_numeric(df['Income'], errors='coerce')\n",
    "df = df.dropna(subset=['Income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aaee275d-1c22-447b-8dc2-6e07f403e673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer-level features\n",
    "customer_features = df.groupby('Customer_ID').agg({\n",
    "    'Age': 'first',\n",
    "    'Income': 'first',\n",
    "    'Gender': 'first'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5b56ba41-b941-464d-8855-7b3c307fd211",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['DayOfWeek', 'Hour', 'IsWeekend'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[134], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Time-series features\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ts_data \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomer_ID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39magg({\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal_Amount\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDayOfWeek\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIsWeekend\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHour\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct_Category\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mmode()[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPayment_Method\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mmode()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     10\u001b[0m })\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1432\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1429\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[0;32m   1431\u001b[0m op \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m-> 1432\u001b[0m result \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39magg()\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1434\u001b[0m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[0;32m   1435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:190\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_dict_like()\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_list_like()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:423\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magg_dict_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    416\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;124;03m    Result of aggregation.\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_or_apply_dict_like(op_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1608\u001b[0m, in \u001b[0;36mGroupByApply.agg_or_apply_dict_like\u001b[1;34m(self, op_name)\u001b[0m\n\u001b[0;32m   1603\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m: engine, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: engine_kwargs})\n\u001b[0;32m   1605\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m com\u001b[38;5;241m.\u001b[39mtemp_setattr(\n\u001b[0;32m   1606\u001b[0m     obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1607\u001b[0m ):\n\u001b[1;32m-> 1608\u001b[0m     result_index, result_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dict_like(\n\u001b[0;32m   1609\u001b[0m         op_name, selected_obj, selection, kwargs\n\u001b[0;32m   1610\u001b[0m     )\n\u001b[0;32m   1611\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[0;32m   1612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:462\u001b[0m, in \u001b[0;36mApply.compute_dict_like\u001b[1;34m(self, op_name, selected_obj, selection, kwargs)\u001b[0m\n\u001b[0;32m    460\u001b[0m is_groupby \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(obj, (DataFrameGroupBy, SeriesGroupBy))\n\u001b[0;32m    461\u001b[0m func \u001b[38;5;241m=\u001b[39m cast(AggFuncTypeDict, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc)\n\u001b[1;32m--> 462\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_dictlike_arg(op_name, selected_obj, func)\n\u001b[0;32m    464\u001b[0m is_non_unique_col \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    465\u001b[0m     selected_obj\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m selected_obj\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnunique() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(selected_obj\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m    467\u001b[0m )\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m selected_obj\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;66;03m# key only used for output\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:663\u001b[0m, in \u001b[0;36mApply.normalize_dictlike_arg\u001b[1;34m(self, how, obj, func)\u001b[0m\n\u001b[0;32m    661\u001b[0m     cols \u001b[38;5;241m=\u001b[39m Index(\u001b[38;5;28mlist\u001b[39m(func\u001b[38;5;241m.\u001b[39mkeys()))\u001b[38;5;241m.\u001b[39mdifference(obj\u001b[38;5;241m.\u001b[39mcolumns, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    662\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 663\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(cols)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m do not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    665\u001b[0m aggregator_types \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m)\n\u001b[0;32m    667\u001b[0m \u001b[38;5;66;03m# if we have a dict of any non-scalars\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m# eg. {'A' : ['mean']}, normalize all to\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;66;03m# be list-likes\u001b[39;00m\n\u001b[0;32m    670\u001b[0m \u001b[38;5;66;03m# Cannot use func.values() because arg may be a Series\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Column(s) ['DayOfWeek', 'Hour', 'IsWeekend'] do not exist\""
     ]
    }
   ],
   "source": [
    "# Time-series features\n",
    "ts_data = df.groupby(['Customer_ID', 'Date']).agg({\n",
    "    'Total_Amount': 'sum',\n",
    "    'DayOfWeek': 'first',\n",
    "    'IsWeekend': 'first',\n",
    "    'Month': 'first',\n",
    "    'Hour': 'first',\n",
    "    'Product_Category': lambda x: x.mode()[0],\n",
    "    'Payment_Method': lambda x: x.mode()[0]\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "00c7d906-8e40-4fd7-8731-f08f640defde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Total_Amount</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>IsWeekend</th>\n",
       "      <th>Month</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Product_Category</th>\n",
       "      <th>Payment_Method</th>\n",
       "      <th>Age_x</th>\n",
       "      <th>Income_x</th>\n",
       "      <th>Gender_x</th>\n",
       "      <th>Age_y</th>\n",
       "      <th>Income_y</th>\n",
       "      <th>Gender_y</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Customer_ID, Date, Total_Amount, DayOfWeek, IsWeekend, Month, Hour, Product_Category, Payment_Method, Age_x, Income_x, Gender_x, Age_y, Income_y, Gender_y, Age, Income, Gender]\n",
       "Index: []"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d02bf8e6-33dd-4130-be4e-ef976e266553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Unique Customer_IDs in customer_features: 0\n",
      "🔍 Unique Customer_IDs in ts_data: 0\n",
      "✅ Number of matching Customer_IDs: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 Unique Customer_IDs in customer_features:\", customer_features['Customer_ID'].nunique())\n",
    "print(\"🔍 Unique Customer_IDs in ts_data:\", ts_data['Customer_ID'].nunique())\n",
    "\n",
    "common_ids = set(ts_data['Customer_ID']).intersection(set(customer_features['Customer_ID']))\n",
    "print(\"✅ Number of matching Customer_IDs:\", len(common_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f19b25f7-722f-4d2b-9b84-d50dbd740712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 302010\n",
      "        Transaction_ID  Customer_ID               Name                 Email  \\\n",
      "48716        3909387.0      25917.0     Lauren Collins    Nathan98@gmail.com   \n",
      "43997        9209374.0      31747.0  Victoria Williams      Gail93@gmail.com   \n",
      "106270       8286848.0      37352.0        Jacob Gates  Samantha69@gmail.com   \n",
      "\n",
      "               Phone                       Address       City         State  \\\n",
      "48716   9.902247e+09  5240 Danielle Ville Apt. 408  Cleveland  Pennsylvania   \n",
      "43997   1.514641e+09             9866 Carlos Trace   Edmonton       Ontario   \n",
      "106270  8.100041e+09     85364 Stephanie Crossroad   Winnipeg       Ontario   \n",
      "\n",
      "        Zipcode Country  ...  Total_Amount Product_Category Product_Brand  \\\n",
      "48716   19544.0     USA  ...    269.733309          Grocery         Pepsi   \n",
      "43997   23353.0  Canada  ...    863.749949            Books  Random House   \n",
      "106270  72237.0  Canada  ...   1393.217741       Home Decor    Home Depot   \n",
      "\n",
      "       Product_Type   Feedback  Shipping_Method Payment_Method Order_Status  \\\n",
      "48716         Juice        Bad         Same-Day    Credit Card   Processing   \n",
      "43997       Fiction    Average         Same-Day    Credit Card    Delivered   \n",
      "106270  Decorations  Excellent         Same-Day     Debit Card      Shipped   \n",
      "\n",
      "        Ratings        products  \n",
      "48716       1.0     Grape juice  \n",
      "43997       2.0       Dystopian  \n",
      "106270      4.0  Picture frames  \n",
      "\n",
      "[3 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = r'C:\\Users\\acer\\Learning\\Python_Contents\\DataSets\\retail_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "print(df.sample(3))  # if rows > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "916f3538-2e75-40e2-8719-c426f6dea110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ts_data shape after merge: (0, 18)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 10)) while a minimum of 1 is required by MinMaxScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[122], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Normalize\u001b[39;00m\n\u001b[0;32m     21\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m---> 22\u001b[0m ts_data[numeric_cols] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(ts_data[numeric_cols])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:450\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_fit(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:490\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    487\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    489\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 490\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    491\u001b[0m     X,\n\u001b[0;32m    492\u001b[0m     reset\u001b[38;5;241m=\u001b[39mfirst_pass,\n\u001b[0;32m    493\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_array_api\u001b[38;5;241m.\u001b[39msupported_float_dtypes(xp),\n\u001b[0;32m    494\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    495\u001b[0m )\n\u001b[0;32m    497\u001b[0m data_min \u001b[38;5;241m=\u001b[39m _array_api\u001b[38;5;241m.\u001b[39m_nanmin(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    498\u001b[0m data_max \u001b[38;5;241m=\u001b[39m _array_api\u001b[38;5;241m.\u001b[39m_nanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1087\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1085\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m-> 1087\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1088\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1089\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1090\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m   1091\u001b[0m         )\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1094\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 10)) while a minimum of 1 is required by MinMaxScaler."
     ]
    }
   ],
   "source": [
    "# Clean ts_data before merge\n",
    "ts_data = ts_data.drop(columns=['Age', 'Gender', 'Income'], errors='ignore')\n",
    "\n",
    "# Ensure Customer_ID is float\n",
    "ts_data['Customer_ID'] = ts_data['Customer_ID'].astype(float)\n",
    "customer_features['Customer_ID'] = customer_features['Customer_ID'].astype(float)\n",
    "\n",
    "# Drop rows with missing critical values\n",
    "customer_features = customer_features.dropna(subset=['Age', 'Income', 'Gender'])\n",
    "\n",
    "# Merge safely\n",
    "ts_data = pd.merge(ts_data, customer_features, on='Customer_ID', how='inner')\n",
    "\n",
    "# Debug print\n",
    "print(\"✅ ts_data shape after merge:\", ts_data.shape)\n",
    "\n",
    "# Define all numeric features\n",
    "numeric_cols = ['Total_Amount', 'DayOfWeek', 'IsWeekend', 'Month', 'Hour', 'Age', 'Income', 'Product_Category', 'Payment_Method', 'Gender']\n",
    "\n",
    "# Normalize\n",
    "scaler = MinMaxScaler()\n",
    "ts_data[numeric_cols] = scaler.fit_transform(ts_data[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8ca3c24f-2f9c-4f2a-8008-d7fd93094a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "def create_sequences(data, customer_id, seq_length=10):\n",
    "    customer_data = data[data['Customer_ID'] == customer_id].sort_values('Date')\n",
    "    if len(customer_data) < seq_length:\n",
    "        return None, None\n",
    "    \n",
    "    features = numeric_cols + ['Product_Category', 'Payment_Method', 'Gender', 'Income']\n",
    "    X, y = [], []\n",
    "    for i in range(len(customer_data) - seq_length):\n",
    "        seq = customer_data.iloc[i:i+seq_length][features]\n",
    "        target = customer_data.iloc[i+seq_length]['Total_Amount']\n",
    "        X.append(seq.values)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5a6d8bc7-8003-4373-a74a-331a2dc457b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Medium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m X, y \u001b[38;5;241m=\u001b[39m create_sequences(ts_data, customer_id)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m     X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      7\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      9\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Medium'"
     ]
    }
   ],
   "source": [
    "# Prepare data for a specific customer\n",
    "customer_id = 48453.0  # Michelle Harrington's ID\n",
    "X, y = create_sequences(ts_data, customer_id)\n",
    "\n",
    "if X is not None:\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    y = np.array(y, dtype=np.float32)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "        LSTM(64, activation='relu', return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        LSTM(32, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_test_actual = scaler.inverse_transform(\n",
    "        np.concatenate([y_test.reshape(-1, 1), np.zeros((len(y_test), len(numeric_cols) - 1))], axis=1)\n",
    "    )[:, 0]\n",
    "    y_pred_actual = scaler.inverse_transform(\n",
    "        np.concatenate([y_pred, np.zeros((len(y_pred), len(numeric_cols) - 1))], axis=1)\n",
    "    )[:, 0]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y_test_actual, label='Actual Spending')\n",
    "    plt.plot(y_pred_actual, label='Predicted Spending', linestyle='--')\n",
    "    plt.title(f'Spending Prediction for Customer {customer_id}')\n",
    "    plt.ylabel('Amount ($)')\n",
    "    plt.xlabel('Days')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Forecast next 7 days\n",
    "    last_sequence = X[-1]\n",
    "    forecast = []\n",
    "    for _ in range(7):\n",
    "        next_pred = model.predict(last_sequence.reshape(1, *last_sequence.shape))\n",
    "        forecast.append(next_pred[0, 0])\n",
    "\n",
    "        new_row = last_sequence[-1].copy()\n",
    "        new_row[0] = next_pred[0, 0]  # Update Total_Amount\n",
    "        new_row[1] = (new_row[1] + 1) % 7  # Update DayOfWeek\n",
    "        new_row[2] = 1 if new_row[1] in [5, 6] else 0  # Update IsWeekend\n",
    "        last_sequence = np.vstack([last_sequence[1:], new_row])\n",
    "\n",
    "    forecast_amounts = scaler.inverse_transform(\n",
    "        np.concatenate([np.array(forecast).reshape(-1, 1),\n",
    "                        np.zeros((7, len(numeric_cols) - 1))], axis=1)\n",
    "    )[:, 0]\n",
    "\n",
    "    print(\"\\nNext 7 Days Forecast:\")\n",
    "    for i, amount in enumerate(forecast_amounts):\n",
    "        print(f\"Day {i + 1}: ${amount:.2f}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Not enough data for customer {customer_id} (need at least 30 transactions)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "28d71b8c-9891-4f74-83aa-be536ca389d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data[ts_data['Customer_ID'] == 37249.0].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a36d77ef-b555-416b-b981-6115b9c0ddac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "customer_counts = ts_data['Customer_ID'].value_counts()\n",
    "eligible_customers = customer_counts[customer_counts >= 30].index.tolist()\n",
    "\n",
    "print(eligible_customers[:5])  # Shows first 5 customers with >= 30 transactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ee3db1ef-2110-486b-b5cc-1dbd09c73e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    86753.000000\n",
      "mean         3.430913\n",
      "std          1.728154\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          3.000000\n",
      "75%          4.000000\n",
      "max         13.000000\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(ts_data['Customer_ID'].value_counts().describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "56d290e4-c4b8-435d-9992-581bc1ebe639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48453.0, 49274.0, 99355.0, 60341.0, 35276.0]\n"
     ]
    }
   ],
   "source": [
    "eligible_customers = customer_counts[customer_counts >= 10].index.tolist()\n",
    "print(eligible_customers[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d9ad9e14-0c32-461e-aea6-5e909a9d99e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtype)\n",
    "print(y_train.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a4b915-09ac-46d8-a95b-17693f1d71a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (base)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
